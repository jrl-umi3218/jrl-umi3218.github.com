
- id: janus
  title: "Janus"
  longtitle: "Team Janus - ANA Avatar XPRIZE"
  year-start: 2018
  year-end: 2022
  active: true
  url: "./janus/team-janus.html"
  partners: [cnrs,lirmm,doublegiken]
  description: "
<p>In Roman mythology, Janus represents the transition from the past to the future, like the one we are seeing today with new technologies. It also represents bridges and connections, like the ones we are building between humans and robots: two entities into the same body.</p>

<p>JANUS is a bi-located team that gathers expertise from the Japanese National Institute of Advanced Industrial Science and Technology (AIST) and the French National Centre for Scientific Research CNRS (CNRS), namely CNRS-AIST Joint Robotics Laboratory (JRL) and <a href=https://www.lirmm.fr/>LIRMM</a>, <a href=https://www.lirmm.fr/lirmm_eng/research/teams/idh>Interactive Digital Human</a> laboratory in Montpellier. These teams have extensive experience in humanoid robotics, haptics, brain computer interfaces, control, telerobotics and telepresence, embodiment and physical avatars. AIST is the co-developer with Kawada industries of the world renown HRP humanoid families and the main developer of the HRP Miim, the first effectively walking geminoid called cybernetic human and has extensive expertise in humanoid robotics. CNRS posses the only HRP-4 humanoid present in Europe. CNRS and AIST to some extent, were also partners of the EU Virtual Embodiment and Robotic Re-Embodiment (VERE) project where a telepresence embodiment station featuring advanced multi-modal feedback decodes the participant’s motor intentions at the EEG brain level to control humanoid robots even over large distances. CNRS with AIST joint efforts in the last EU Comanoid project where humanoid robots are envisioned to work in large-scale aeronautics manufacturing.</p>

<b>Why are we competing in ANA Avatar XPRIZE?</b>

<p>Our main mission is to create and advance knowledge for the well-being of humanity and society. Challenging competitions like ANA Avatar XPRIZE are the technological catalyzers for new ideas and technologies. Furthermore, the Covid19 outbreak highlighted the need for such an avatar technology in healthcare services, frail persons homes, as well as many other economical and societal sectors.</p>

<b>Which have been the biggest challenges?</b>

<p>The biggest challenge is the seamless integration of existing and new technologies into a reliable architecture. Particularly, the transparency of the teleoperation is extremely challenging in anthropomorphic robotic systems. When using a humanoid robot as an avatar, the sensory feedback scales in complexity. For example, how do you provide the dynanmic balance awareness to the human operator? How do you alleviate the lack of degrees of freedom? How do you conceive a reliable loco-manipulation shared control?</p>
"
- id: visadapt
  title: "Visadapt"
  longtitle: "CNRS INSIS PEPS Visadapt - Adaptative Catadioptric Vision"
  year-start: 2021
  year-end: 2022
  active: true
  partners: [inria,polytechlille,upjv]
  description: "
<p>Visadapt is an exploratory project funded by the PEPS &ldquo;Mechanics of the future&rdquo; program of CNRS&rsquo; Institute of Engineering and Systems Sciences (INSIS). In this project, CNRS-AIST JRL is partnering with Inria and Polytech Lille members of CRIStAL (France) and UPJV, MIS lab (France) with the aim of creating a new camera of highly non-linear field-of-view, enabled by soft robot mirror. The interest is to automatically adapt the resolution of the camera to the scene content, i.e. low in uniform or not interesting areas but high in informative areas or interesting regarding the application (e.g. body, face, geometric features, etc).</p>
    <h4>The goals are:</h4>
    <ul>
      <li>To design a new mirror material capable of deformations while keeping high quality reflection</li>
      <li>To model and compute efficiently the desired shape of the mirror soft robot as function of a field-of-view distribution</li>
			<li>To control the deformation from visual input</li>
    </ul>
A realistic simulator and a first prototype are the expected results.
</p>
"
- id: hadros
  title: "HaDROs"
  longtitle: "CNRS GDR ISIS HaDROs - HDR panoramic vision for SLAM in scenes of large range of radiance"
  year-start: 2021
  year-end: 2023
  active: true
  partners: [insarennes,upjv]
  description: "
<p>HaDROs is an exploratory project funded by CNRS&rsquo; Special Interest Group on Information, Signal, Image and Vision (GDR ISIS). In this project, CNRS-AIST JRL is partnering with INSA members of IRISA (France) and UPJV, MIS lab (France) with the aim of enabling visual Simultaneous Localization And Mapping (SLAM) in  envrionments of challenging lighting, i.e. where we can find both dark shadowed and very bright areas at once. HaDROs leverages the recently introduced panoramic High Dynamic Range (HDR) real-time camera <a href=https://hal.archives-ouvertes.fr/hal-03130948 target=_blank>HDROmni</a> and works on multi-exposure / multi-map SLAM.</p>
    <h4>The goals are:</h4>
    <ul>
      <li>To accurately calibrate the HDROmni camera despite the various exposures acuired at once</li>
      <li>To generalize the multi-map SLAM to multi-exposure</li>
			<li>To enable assistive visual feedback for electric powered wheelchair users even when the surrounding illumination is challenging</li>
    </ul>
The HaDROs system will be integrated on an assistive wheelchair of INSA Rennes (France) and assessed with real users. 
</p>
"
- id: dvsstraight
  title: "DVS-Straight"
  longtitle: "AIST ITH International Collaboration DVS-Straight - Direct Visual Servoing with optimal robot trajectories"
  year-start: 2021
  year-end: 2025
  active: true
  partners: [utbm,upjv]
  description: "
<p>DVS-Straight is an international collaboration project funded by the ITH department of AIST. In this project, CNRS-AIST JRL is partnering with UTBM, CIAD lab (France) and UPJV, MIS lab (France) with the aim of mastering the robot trajectories during image-based visual servoing directly using the dense brightness of captured images as input of the control law (Direct Visual Servoing: DVS). Indeed, DVS is first known for its submillimetric precision and recently for a quite large convergence domain, e.g. with <a href=https://hal.archives-ouvertes.fr/hal-03155667 target=_blank>DDVS</a>. However, trajectories are not always satisfactory.</p>
    <h4>The goals are:</h4>
    <ul>
      <li>To develop an international network of labs and researchers to work on the DVS-Straight topic</li>
      <li>To exploit better the control theory for improving the conditioning</li>
			<li>To encapsulate DVS in multi-objective control frameworks for condisering explicit trajectory constraints</li>
			<li>To research the optimal field-of-view maximizing the motion perceptibility</li>
    </ul>
all for better behavior of DVS-based control laws and hence applicability in a much larger variety of scenarios and contexts. </p>
<p>A series of international workshops will be organized to share the research, the results and the open-source software as well as to develop the research community on these topics.
</p>
"
- id: comanoid
  title: "COMANOID"
  longtitle: "Multi-Contact Collaborative Humanoids in Aircraft Manufacturing"
  year-start: 2015
  year-end: 2019
  active: false
  url: "http://www.comanoid.eu"
  partners: [cnrs, dlr, inria, sapienza, airbus-gi]
  description: "<p>COMANOID stands for -Multi-Contact Collaborative Humanoids in Aircraft Manufacturing- is a RIA four-year European research project that started in January 2015 as part of the Horizon H2020 program.</p>

  <p>COMANOID aims at deploying humanoid robots to achieve non-added value tasks that have been identified by Airbus Group in aircraft assembly operations. The project focuses on showing precise accessibility (namely into areas where wheeled robots cannot be deployed) through whole body multi-contact planning motion with advanced embedded 3D dense SLAM localization and visuo-force servoing capabilities. Because the robots evolve in human worker co-localized spaces, safety issues will be specifically accounted for. The results of COMANOID will be showcased in a 1:1 scale demonstrator of a real aircraft using two humanoid robots: the HRP-4 position controlled humanoid robot provided by CNRS partner and the TORO torque controlled humanoid robot provided by DLR partner.</p>
    <h4>Goals</h4>
    <ul>
      <li>To investigate the deployment of humanoid robots solutions in Airbus assembly operations that are laborious and inaccessible for wheeled platforms.</li>
      <li>To achieve Human-robot safe and operationally efficient collaboration.</li>
    </ul>"
- id: koroibot
  title: "KoroiBot"
  longtitle: "Improving humanoid walking capabilities by human-inspired mathematical models, optimization and learning"
  year-start: 2013
  year-end: 2016
  active: false
  url: "http://www.koroibot.eu/"
  partners: [heidelberg,cnrs,kit,iit,tudelft,wis,utubingen]
  description: "<p>Teaching two-legged robots a stable, robust “human” way of walking – this is the goal of the international research project KoroiBot, which is named after Koroibos of Elis, the first recorded Olympic champion in history. KoroiBot is funded by the European Union from October 2013 on for three years and gathers an interdisciplinary consortium from the areas of robotics, mathematics and cognitive sciences.</p>
  <p>Whether as rescuers in disaster areas, household helps or as “colleagues” in modern work environments: there are numerous possible areas of deployment for humanoid robots in the future. One of the major challenges on the way is to enable robots to move on two legs in different situations, without falling – even in unknown rough terrain and under possible perturbations.</p>
    <p>In the KoroiBot project, we will study the way humans walk e.g. on stairs and slopes, on soft and slippery ground or over beams and seesaws, and create mathematical models. Besides developing new optimization and learning methods for walking on two legs, we  aim to implement them in practice on real robots. In addition, the research results are to flow into planning new design principles for the next generation of robots.</p>
    <p>Besides the targeted use in robotics, we expect possible applications of the methods in medicine, e.g. for controlling intelligent artificial limbs, designing and controlling exoskeletons as well as in computer animation and in game design.</p>

    <p>Financial support by the European Union within the 7th Framework Program under Grant Agreement No. 611909 is gratefully acknowledged.</p>"
- id: robohow
  title: "RoboHow"
  longtitle: "RoboHow"
  year-start: 2012
  year-end: 2016
  active: false
  url: "https://robohow.eu/"
  partners: [bremen,cnrs,epfl,kth,kul,forth,ul,aldebaran,tum]
  description: "<p>Robohow is a four-year European research project that started in February 2012. It aims at enabling robots to competently perform everyday human-scale manipulation activities - both in human working and living environments.</p>
  <p>In order to achieve this goal, Robohow pursues a knowledge-enabled and plan-based approach to robot programming and control.</p>
  <p>The vision of the project is that of a cognitive robot that autonomously performs complex everyday manipulation tasks and extends its repertoire of such by acquiring new skills using web-enabled and experience-based learning as well as by observing humans.</p>"
  videos:
    - title: "Human-Humanoid Joint Haptic Table Carrying Task with Height Stabilization using Vision"
      url: "https://www.youtube.com/watch?v=LnuF41CKq0E"
      img: "http://i1.ytimg.com/vi/LnuF41CKq0E/mqdefault.jpg"
    - title: "Proactivity and Role Switching in a Humanoid-Human Transportation Task"
      url: "https://www.youtube.com/watch?v=kYUdYOIYeZ0"
      img: "http://i1.ytimg.com/vi/kYUdYOIYeZ0/mqdefault.jpg"
- id: vere
  title: "VERE"
  longtitle: "Virtual Embodiment and Robotic Re-Embodiment"
  year-start: 2010
  year-end: 2015
  active: false
  url: "http://www.vereproject.eu/"
  description: "<p>This Integrated Project aims at dissolving the boundary between the human body and surrogate representations in immersive virtual reality and physical reality. Dissolving the boundary means that people have the illusion that their surrogate representation is their own body, and act and have thoughts that correspond to this. The work in VERE may be thought of as applied presence research and applied cognitive neuroscience, and it would also significantly add to scientific knowledge in these areas.</p>"
  videos:
    - title: "Humanoid robot embodiment with a brain-computer interface"
      url: "https://www.youtube.com/watch?v=ekP1oxD6Vj0"
      img: "http://i1.ytimg.com/vi/ekP1oxD6Vj0/mqdefault.jpg"
    - title: "Multitask Humanoid Control with a Brain-Computer Interface: user experiment with HRP-2"
      url: "https://www.youtube.com/watch?v=6bynYqmVVck"
      img: "http://i1.ytimg.com/vi/6bynYqmVVck/mqdefault.jpg"
- id: robot_at_cwe
  title: "Robot@CWE"
  longtitle: "Robot@CWE"
  year-start: 2007
  year-end: 2009
  active: false
  description: "<p>The main objective of this STREP is to research and demonstrate integrative concepts of advanced robotic systems, to be seen as collaborative agents, in various environments working together with humans. We will integrate collaborative robotic systems as active agent operated through various control paradigms within working environment clusters. ROBOT@CWE will design suitable architectures and technologies to achieve this goal. Current developments in robotics tend toward human-centred design raising issues in: human-machine interface, human-robot interaction, working robots, assistive robots, ubiquitous robotics,humanitarian robotics for disaster support and rescue mission, European security, etc.</p>"
- id: kakenhiG_2015
  title: "Sixth Finger"
  longtitle: "Towards natural learning of an additional effector by the human brain"
  year-start: 2015
  year-end: 2017
  active: false
  description: >
    <p>Our brain can readily learn to control new actions with our effectors/limbs, but can it also learn to control new limbs in addition to our current ones? Answering this question will clarify an individual brain’s neuronal limits, for functional augmentation with brain-machine interface (BMI) systems and of plasticity after brain damage. This JSPS (Kakenhi 'houga')multi-disciplinary project with the University of Electro-communication in Tokyo will provide a crucial understanding of the <i>unused capabilities</i> of the human brain in regard to effector control and will enable a human to use this capability to incorporate an additional artificial limb naturally into his body schema.</p>
- id: kakenhiG_2013
  title: "AnxCon"
  longtitle: "Understanding and controlling the effects of anxiety on motor behavior"
  year-start: 2013
  year-end: 2016
  active: false
  description: >
    <p>This JSPS ('Kakenhi Kiban B') project investigates the effects of cognitive anxiety associated with observation of other individuals and competition on one's own motor behavior. In Collboration with <a href="https://cinet.jp/english/" target="_self">Centre for Information and Neural Networks (CINET)</a> in Osaka, <a href="http://www.nifs-k.ac.jp/" target="_self">National Institute of Fitness and Sports</a> in Kanoya, and <a href="http://www.chukyo-u.ac.jp/" target="_self">Nagoya Chukyo University</a>, we are using cognitive neuroscience experiments and computational modelling to acquire a quantitative measure of motor deteriorations due to anxiety, and investigate how non-human agents like robots may be used to influence human behaviors.</p>
- id: jst_mirai
  title: "CareAvatar"
  longtitle: "Remotification of physical interaction for resilient society"
  year-start: 2021
  year-end: 2023
  active: true
  description: >
    <p>We aim to create a society that is resilient to infectious diseases, by using avatar robots to enable telework for essential workers whose work requires physical contact with people. ​<br>We will conduct research and development of a tele-physical caregiving service that enables telework in caregiving.​<br>In this service, a caregiver operates a nursing care avatar at the nursing care site from a remote location via a digital twin of the nursing care site built in cyberspace to perform nursing care tasks. To realize this service, we will conduct research and development on the following three technologies.​<br><ol><li>Haptic sensing technology that captures complex physical information as a distribution on a three-dimensional curved surface,</li><li>Technology for understanding and reproducing the movements of a remote caregiver, and</li><li>Safety standards that are essential for social acceptance.​</li></ol></p>
- id: kakenhi_wakate2019_kumagai
  title: "JSPS TaskPlanning"
  longtitle: "Development of task planning system for autonomous task execution"
  year-start: 2019
  year-end: 2022
  active: true
  description: >
    <p>This project is a four-year research project founded by JSPS Kakenhi Grant-in-Aid for Early-Career Scientists (19K20380). Our ultimate goal is enabling a robot to autonomously generate and perform a sequence of target tasks considering task dependencies, constraints of a robot and the surrounding environment.​ To achieve this goal, we will conduct research and development on the following three topics.​<br><ol><li>Task management system which can perform error recovery and parallel processing of a task sequence based on the dependency of tasks.</li><li>Motion planning technology which can generate feasible whole-body motion for a robot to reach the destination and perform required tasks considering kinematics and dynamics constraints.</li><li>Semantic environmental memorization to find objects which are neccesary for task execution.​</li></ol></p>
- id: ryouikikoubo_2021
  title: "Tuning-free control"
  longtitle: "Data-driven online adaptive model/control parameters for tuning-free motion generation."
  year-start: 2021
  year-end: 2023
  active: true
  description: "
    <p> Controlling the dynamics of complex systems requires identifying and tuning more and more parameters, leading to increasing adaptation times for new tasks or new robots. In this project, we plan to make this process automatic and online to constantly improve the performance during the robot operation. Classical control techniques, together with statistical tools and machine learning will be exploited to this end.</p>"
