---
layout: default
title: CNRS-AIST JRL - Humanoid Lab
---

<div class="breadcrumbs-container">
<div class="container">
  <div class="row">
    <div class="col-lg-12">
      <ol class="breadcrumb">
        <li><a href="/index_en.html">Home</a>
        </li><li class="active">ヒューマノイド研究室 (筑波大学)</li></ol>
      <h1 class="page-header">ヒューマノイド研究室
	<small>
	[<a href="{{site.baseurl}}/en/humanoid_lab.html">EN</a>
	/
	<a href="{{site.baseurl}}/en/humanoid_lab_jp.html">JP</a>]
	  <br/>
	  <a href="https://www.tsukuba.ac.jp/education/g-courses-g-list-prev-cooperatives/" target="blank_">筑波大学 - 連携大学院 <span class="glyphicon glyphicon-globe" style="font-size: small;"></span></a></small></h1>
    </div>
  </div>
</div>
</div>


<!-- Page Content -->
<div class="container">

  <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tbody>
      <tr>
	<td style="padding: 20px; border-radius:15px">
      <table border="0" width="100%" cellpadding="7">
        <tbody>
          <tr>
            <td width="330" align="left" rowspan="2">
	      <img src="{{site.baseurl}}/en/assets/humanoidlab/four_humanoids.jpg" width="300" style="border-radius:15px">
	      <br>
	      <br>
	      <img src="{{site.baseurl}}/en/assets/humanoidlab/combined_logo.png" width="300" style="border-radius:15px">
	    </td>
            <td>
	      <p align="justify">
		ヒューマノイド研究室は、<a href="https://www.tsukuba.ac.jp/education/g-courses-g-list-prev-cooperatives/">連携大学院制度</a>によって筑波大学メインキャンパスから約5kmの産総研にあるCNRS-AIST JRLに設置された筑波大学の研究室です。金広教授（連携大学院）の指導のもと、大学院生が技術研修生・<a href="https://www.aist.go.jp/aist_j/business/alliance/ra/ra_index.html">RA</a>としてJRLに所属することができます。
	      </p>
	      <p align="justify">
		この研究室では、大学院生が国内外の研究者とともに、さまざまなロボットを用いて様々な研究テーマに取り組むことができるユニークな機会を提供しています。主な研究テーマは、タスクや動作のプランニング、制御、人間や周辺環境とのマルチモーダルインタラクション、認知ロボティクスなどです。研究室のほとんどのメンバーはバイリンガルなので、日本語を話す学生だけでなく、英語を話す学生も研究室に参加することを推奨しています。
	      </p>
	    </td>
	    <td valign="top" align="center" style="padding-left: 20px;padding-bottom: 20px" width="150" >
	      <a href="{{site.baseurl}}/en/members/member-kanehiro.html">
	      <img src="{{site.baseurl}}/en/assets/members/kanehiro.jpg" width="100" style="border-radius:50px">
	      </a>
	      <p align="center">KANEHIRO Fumio<br>
		<b>金広 文男</b></p>
	      <p style="margin-top: -0.5em; font-size:80%"><i>
	      f-kanehiro_*_aist.go.jp</i></p>
	      <p style="margin-top: -0.5em; background-color:#e0f0fe">教授</p>
	    </td>
	  </tr>
	  <tr>
	    <td colspan="2">
	      <p align="justify">
		当研究室では、常に優秀で意欲的な大学院生を募集しています。筑波大学大学院システム情報工学研究群知能機能システム学位プログラム修士課程または博士課程の<a href="https://www.ap-graduate.tsukuba.ac.jp/course/sie/">入試（夏と冬に試験を実施）</a>を受験し合格した方が参加できます。</p>

	      <p align="justify"><b>
		  興味のある方は、出願手続きを始める前に、研究室または金広教授に直接お問い合わせください。</b></p>

	      <!-- <p>Check out our YouTube channel <a href="https://www.youtube.com/channel/UCYwHCdMHAKYZJ2MQIoTavVQ"> here. </a></p> -->
	      <p align="justify">(このページは、在校生によって管理されています。)</p>
	    </td
	  </tr>
        </tbody>
      </table>

      <div class="row">
	<h3 class="page-header">研究内容</h3>
	  <!-- content -->
	  <table border="0" width="100%" cellpadding="17" cellspacing="0">
            <tbody>
              <tr valign="top">
		<td style="padding: 20px;background-color:#e0f0fe; border-radius:15px">
		  <table border="0" width="100%" cellpadding="0" cellspacing="0" >
		    <tbody>
                      <tr>
			<td><b><font size="+1">Simultaneous localization and mapping(SLAM) in dynamic environment</font></b></td>
			<td>&nbsp;</td>
			<td rowspan="3" valign="top" width="200">&nbsp;<img src="{{site.baseurl}}/en/assets/humanoidlab/hl_01_slam.jpg" height="227" border="0"></td>
                      </tr>
                      <tr>
			<td height="10"></td>
			<td height="10"></td>
                      </tr>
                      <tr>
			<td valign="top">Nowadays, SLAM in the dynamic environment has become a popular topic.
			  This problem is called dynamic SLAM where many solutions have been proposed to segment
			  out the dynamic objects that bring errors to camera tracking and subsequent 3D reconstruction.
			  However, state-of-the-art dynamic SLAM methods face the problems of accuracy and speed, which
			  is due to the fact that one segmentation algorithm cannot guarantee both points at the same time.
			  We propose a multi-purpose dynamic SLAM framework to provide a variety of selections for segmentation,
			  each has its applicable scene. Besides, if the user selects the semantic segmentation, the object-oriented
			  semantic mapping is beneficial for high level robotic tasks. </td>
			<td width="50">&nbsp;</td>
                      </tr>
		    </tbody>
		  </table>
		</td>
              </tr>
            </tbody>
	  </table>

	  <br>
	  <br>

	  <!-- content -->
	  <table border="0" width="100%" cellpadding="17" cellspacing="0">
            <tbody>
              <tr valign="top">
		<td style="padding: 20px;background-color:#e0f0fe; border-radius:15px">
		  <table border="0" width="100%" cellpadding="0" cellspacing="0">
		    <tbody>
                      <tr>
			<td><b><font size="+1">6-DoF Object Pose Estimation</font></b></td>
			<td>&nbsp;</td>
			<td rowspan="3" width="312"><img src="{{site.baseurl}}/en/assets/humanoidlab/hl_02.png" width="311" border="0"></td>
                      </tr>
                      <tr>
			<td height="10"></td>
			<td height="10"></td>
                      </tr>
                      <tr>
			<td valign="top">For a humanoid robot to interact with objects in its surrounding environment,
			  it is essential for the robot to find the position and orientation of the object relative to
			  itself - often through the use of its vision sensors. The 3D position and roll, pitch, yaw
			  rotation together comprise the 6 degrees-of-freedom pose of the object. For precise grasping
			  and manipulation of tools, this pose needs to be estimated with a  high degree of accuracy.
			  Further, we desire robustness against challenging lighting conditions, occlusions, and non-availability
			  of dense and accurate object models. This work mainly involves the use of Deep Learning based strategies
			  for solving problems in this sphere.
			</td>
			<td width="50">&nbsp;</td>
                      </tr>
		    </tbody>
		  </table>
		</td>
              </tr>
            </tbody>
	  </table>

	  <br>
	  <br>

	  <!-- content -->
	  <table border="0" width="100%" cellpadding="17" cellspacing="0">
            <tbody>
              <tr valign="top">
		<td style="padding: 20px;background-color:#e0f0fe; border-radius:15px">
		  <table border="0" width="100%" cellpadding="0" cellspacing="0">
		    <tbody>
                      <tr>
			<td><b><font size="+1">Enhanced Visual Feedback with Decoupled Viewpoint Control in Immersive Teleoperation using SLAM</font></b></td>
			<td>&nbsp;</td>
			<td rowspan="3" width="312"><img src="{{site.baseurl}}/en/assets/humanoidlab/hl_cslam.png" width="311"  border="0"></td>
                      </tr>
                      <tr>
			<td height="10"></td>
			<td height="10"></td>
                      </tr>
                      <tr>
			<td valign="top">During humanoid robot teleoperation, there is a noticeable delay between the motion of the
				operator’s and robot’s head. This latency could cause the lag in visual feedback, which decreases the
				immersion of the system, may cause some dizziness and reduce the efficiency of interaction in teleoperation
				since operator needs to wait for the real-time visual feedback. To solve this problem, we
				developed a decoupled viewpoint control solution which allows the operator to
				obtain the visual feedback changes with low-latency in VR and to increase the reachable
				visibility range. Besides, we propose a complementary SLAM solution which uses the reconstructed mesh to
				complement the blank area that is not covered by the real-time robot’s point cloud visual feedback. The
				operator could sense the robot head’s real-time orientation by observing the pose of the point cloud.
			</td>
			<td width="50">&nbsp;</td>
                      </tr>
		    </tbody>
		  </table>
		</td>
              </tr>
            </tbody>
	  </table>

      </div>

      <div class="row">
	<h3 class="page-header">構成メンバー</h3>
        <table width="100%" border="0" cellspacing="0" class="table table-striped">
          <tbody>
            <tr>
	      <th width="25%">氏名</th>
	      <th width="25%">学年</th>
	      <th width="25%">メールアドレス<br>
		_*_を@に変えて送信ください</th>
            </tr>
	    <!--
		<tr>
		  <td><a href="{{site.baseurl}}/en/members/member-kanehiro.html">金広 文男</a></td>
		  <td>連携大学院教授</td>
		  <td width="25%">f-kanehiro_*_aist.go.jp</td>
		</tr>
		-->
	    <tr>
	      <td><a href="{{site.baseurl}}/en/members/member-qin.html">覃 毅力</a></td>
	      <td>博士課程4年</td>
	      <td width="25%">yili.tan_*_aist.go.jp</td>
            </tr>
            <tr>
	      <td><a href="{{site.baseurl}}/en/members/member-sun.html">孫 楽源</a></td>
	      <td>博士課程3年</td>
	      <td width="25%">son.leyuansun_*_aist.go.jp</td>
            </tr>
            <tr>
	      <td><a href="{{site.baseurl}}/en/members/member-singh.html">Rohan Pratap Singh</a></td>
	      <td>博士課程2年</td>
	      <td width="25%">rohan-singh_*_aist.go.jp</td>
            </tr>
            <tr>
	      <td>Xinchi Gao</td>
	      <td>修士課程1年</td>
	      <td width="25%"></td>
            </tr>
            <tr>
	      <td>屋宮 友哉</td>
	      <td>修士課程1年</td>
	      <td width="25%"></td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="row">
	<div class="col-lg-12">
	  <h3 class="page-header">連絡先</h3>
          <table width="100%">
            <tbody>
              <tr align="center">
		<td>
		  <iframe src="https://www.google.com/maps/embed?pb=!1m28!1m12!1m3!1d25795.692830871016!2d140.1074103178154!3d36.082234076560354!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!4m13!3e6!4m5!1s0x60220bff99f57b0b%3A0x1cad40e7632fb4b8!2zVW5pdmVyc2l0eSBvZiBUc3VrdWJhIOetkeazouWkpw!3m2!1d36.103866599999996!2d140.1020979!4m5!1s0x60220cc567b824f5%3A0xecc14922713a4044!2z44CSMzA1LTg1NjAgSWJhcmFraSwgVHN1a3ViYSwgVW1lem9ubywgMSBDaG9tZeKIkjEtMSDkuK3lpK7nrKwx44Gk44GP44Gw5pys6YOo5oOF5aCx5oqA6KGT5YWx5ZCM56CU56m25qOfIFRzdWt1YmEgQ2VudGVyLCBBSVNUOiBOYXRpb25hbCBJbnN0aXR1dGUgb2YgQWR2YW5jZWQgSW5kdXN0cmlhbCBTY2llbmNlIGFuZCBUZWNobm9sb2d5!3m2!1d36.0624307!2d140.1356783!5e0!3m2!1sen!2sjp!4v1650429789876!5m2!1sen!2sjp" width="600" height="450" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
		</td>
              </tr>
            </tbody>
          </table>
	</div>
      </div>

      </td></tr>
    <tbody>
  </table>
</div>
<!-- /.container -->

